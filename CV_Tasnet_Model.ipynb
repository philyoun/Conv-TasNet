{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV_TasNet - Model Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Unknownerror, cudnn 어쩌고저쩌고 에러\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tf.__version__:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import soundfile as sf\n",
    "# sys.getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.__version__ 2.5.0에서는 keras.layers.DepthwiseConv2D는 있는데 1D는 없어서 직접 만들어봄\n",
    "class DepthConv1D(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=1, padding='causal',\n",
    "                 dilation_rate=1, bias_initializer='zeros', use_bias=True, **kwargs):\n",
    "        super(DepthConv1D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.bias_initializer=keras.initializers.get(bias_initializer)\n",
    "        self.use_bias = use_bias\n",
    "    def build(self, batch_input_shape):\n",
    "        self.batch_size = batch_input_shape[0]\n",
    "        self.channels = batch_input_shape[-1] # channels_last\n",
    "        self.layers = []\n",
    "        for i in range(self.channels):\n",
    "            self.layers.append(keras.layers.Conv1D(self.filters, self.kernel_size, self.strides,\n",
    "                    padding=self.padding, dilation_rate=self.dilation_rate, use_bias=False, \n",
    "                                                   name='depth_conv{}'.format(i)))\n",
    "        if self.use_bias:\n",
    "            self.b = self.add_weight(name='conv1d_bias',\n",
    "                        shape=(self.filters*self.channels, ), \n",
    "                        initializer=self.bias_initializer, trainable=True) # add bias\n",
    "        super(DepthConv1D, self).build(batch_input_shape)\n",
    "    def call(self, inputs):\n",
    "        # channel별로 쪼개서, 각각의 keras.layers.Conv1D를 거치고,\n",
    "        # 그걸 다시 stack.\n",
    "        results = []\n",
    "        for i in range(self.channels):\n",
    "            results.append(self.layers[i](inputs[:, :, i:i+1]))\n",
    "        stacked = tf.stack(results, axis=2) # input should be [batch_size, timesteps, channels]\n",
    "        if self.use_bias:\n",
    "            reshaped = tf.reshape(stacked, [self.batch_size, -1, self.channels*self.filters]) + self.b\n",
    "        else:\n",
    "            reshaped = tf.reshape(stacked, [self.batch_size, -1, self.channels*self.filters])\n",
    "        return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 논문 Figure 1. (C)의 1-D Conv block design 따라서 만들어보면,\n",
    "class ConvBlock(keras.layers.Layer):\n",
    "    def __init__(self, h_filters, kernel_size, dilation_rate,\n",
    "                 sc_filters, res_filters, **kwargs):\n",
    "        '''\n",
    "        h_filters: num of channels in convolutional blocks\n",
    "        kernel_size: kernel size in convolutional blocks\n",
    "        sc_filters: num of channels of 1x1-conv skip-connection\n",
    "        res_filters: num of channels of 1x1-conv residual path\n",
    "        '''\n",
    "        super(ConvBlock, self).__init__(**kwargs)\n",
    "        # 1x1-conv, D-conv가 있고 각각 다음에 PReLU, Normalization이 와야됨\n",
    "        self.point_conv = keras.layers.Conv1D(h_filters, kernel_size=1, # dilation_rate=dilation_rate,\n",
    "                                use_bias=False, name='point_conv') # pointwise conv to begin with. 1x1-conv는 dilation_rate 의미없음.\n",
    "        self.prelu1 = keras.layers.PReLU(shared_axes=-1, name='1st_prelu')\n",
    "        self.norm1 = keras.layers.LayerNormalization(axis=-1, name='1st_norm')\n",
    "        \n",
    "        \n",
    "        self.depth_conv = DepthConv1D(1, kernel_size=kernel_size, strides=1, padding='causal',\n",
    "                            dilation_rate=dilation_rate, use_bias=False, name='depth_conv') # depthwise conv\n",
    "        self.prelu2 = keras.layers.PReLU(shared_axes=-1, name='2nd_prelu')\n",
    "        self.norm2 = keras.layers.LayerNormalization(axis=-1, name='2nd_norm')\n",
    "        \n",
    "        self.point_conv2 = keras.layers.Conv1D(sc_filters, kernel_size=1, \n",
    "                                        use_bias=False, name='sc_conv') # linear, skip-connection 1x1 conv\n",
    "        self.point_conv3 = keras.layers.Conv1D(res_filters, kernel_size=1, \n",
    "                                        use_bias=False, name='res_conv') # linear, residual path 1x1 conv\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.point_conv(inputs)\n",
    "        x = self.prelu1(self.norm1(x)) # after 1x1-conv\n",
    "        x = self.depth_conv(x)\n",
    "        x = self.prelu2(self.norm2(x)) # after depth-conv\n",
    "        skip_connection = self.point_conv2(x)\n",
    "        residual = self.point_conv3(x)\n",
    "        return skip_connection, inputs + residual # activation 따로 없음. skip-connection은 for sum, residual은 input for the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test1\n",
    "# num_channels = 128 # this equals number of residual filters\n",
    "# x = tf.random.normal((64, 16, num_channels)) # 32 samples, 16 timesteps, 8 channels\n",
    "# cblock3 = ConvBlock(h_filters=512, kernel_size=3, dilation_rate=1, sc_filters=128, res_filters=num_channels)\n",
    "# sc_output3, res_output3 = cblock3(x)\n",
    "# print(sc_output3.shape)\n",
    "# print(res_output3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv Blocks가 달라지는 dilation_rate와 함께 stack되는게 C_Blocks\n",
    "def C_Blocks(num_of_blocks, h_filters, kernel_size, sc_filters, res_filters):\n",
    "    total = []\n",
    "    for i in range(num_of_blocks):\n",
    "        dilation_rate = 2**i\n",
    "        total.append(ConvBlock(h_filters, kernel_size, dilation_rate, \n",
    "#                               sc_filters, res_filters, name='{}_block'.format(i)))\n",
    "                               sc_filters, res_filters))\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best\n",
    "num_spks = 2\n",
    "n_filters = 512 # enc_dim\n",
    "length = 16\n",
    "b_filters = 128 # feature_dim\n",
    "h_filters = 512\n",
    "sc_filters = 128\n",
    "p = 3\n",
    "x = 8\n",
    "r = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-second long segments, monophonic\n",
    "sample_inputs = keras.Input((16000, 1), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of basis signals = 512만큼 filters를 펌핑하고,\n",
    "encoder = keras.layers.Conv1D(n_filters, kernel_size=length, strides=length//2, \n",
    "                              use_bias=False, activation='sigmoid')\n",
    "sample_encoder_outputs = encoder(sample_inputs)\n",
    "print('Sample encoder outputs shape:', sample_encoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layernorm = keras.layers.LayerNormalization()\n",
    "bottleneck_layer = keras.layers.Conv1D(b_filters, kernel_size=1,\n",
    "                                use_bias=False, name='bottleneck_layer')\n",
    "\n",
    "before_blocks = layernorm(sample_encoder_outputs)\n",
    "before_blocks = bottleneck_layer(before_blocks)\n",
    "print('Before blocks shape:', before_blocks.shape) # 여기까지가 separation module의 1-D Conv 들어가기 직전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = []\n",
    "for i in range(r):\n",
    "    blocks += C_Blocks(x, h_filters, p, sc_filters, b_filters)\n",
    "print('Total block numbers:', len(blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 separation module에 있는 1-D Conv Block들을 통과하면서 나오는 결과물들\n",
    "# skip-connection results, residual results. 전자는 summed up, 후자는 next block의 input\n",
    "res_output = before_blocks\n",
    "after_blocks = tf.zeros((BATCH_SIZE, sample_encoder_outputs.shape[1], sc_filters))\n",
    "for i, block in enumerate(blocks):\n",
    "    sc_output, res_output = block(res_output)\n",
    "    after_blocks += sc_output\n",
    "    print('Number {} block done'.format(i), end=\"\\t\")\n",
    "print()\n",
    "print('After blocks outputs shape:', after_blocks.shape) # 이게 모든 skip connections들의 합. [32, 16, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PReLU(), pointwise conv, sigmoid 를 통과해야 이게 masks\n",
    "prelu_layer = keras.layers.PReLU(shared_axes=-1)\n",
    "bottleneck_later = keras.layers.Conv1D(n_filters*2, kernel_size=1, use_bias=False,\n",
    "                                      name='bottleneck_layer2') # 여기서 곱하기 2, pointwise Conv1D\n",
    "after_separation = prelu_layer(after_blocks)\n",
    "after_separation = bottleneck_later(after_separation)\n",
    "print(after_separation.shape) # [32, 16, 128*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = tf.reshape(after_separation, shape=(BATCH_SIZE, num_spks, -1, n_filters))\n",
    "masks = keras.activations.softmax(reshaped, axis=1) # 이 masks에 unit summation constraint 어떻게 주지??\n",
    "print('masks.shape:', masks.shape) # 이 mask의 shape이 (bs, num_spks, length, h_filters)여야한다는거아냐\n",
    "\n",
    "# encoder_outputs와 masks를 elementwise multiplication을 함.\n",
    "separation_outputs = keras.layers.Multiply()([sample_encoder_outputs, masks])\n",
    "print('Separation_outputs.shape:', separation_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = []\n",
    "decoders = []\n",
    "for i in range(num_spks):\n",
    "    sep.append(separation_outputs[:, i, :, :])\n",
    "    decoders.append(keras.layers.Conv1DTranspose(1, kernel_size=length, strides=length//2, \n",
    "                                        use_bias=False, name='Decoder_Num{}'.format(i)))\n",
    "decoder_outputs = []\n",
    "for i in range(num_spks):\n",
    "    decoder_outputs.append(decoders[i](sep[i]))\n",
    "\n",
    "outputs1 = decoder_outputs[0]\n",
    "outputs2 = decoder_outputs[1]\n",
    "outputs = tf.concat([outputs1, outputs2], axis=-1)\n",
    "print('Final outputs shape:', outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tasnet = keras.Model(sample_inputs, outputs)\n",
    "cv_tasnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tasnet.optimizer = keras.optimizers.Adam(0.001, clipnorm=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_lists = cv_tasnet.trainable_variables\n",
    "non_trainable_lists = cv_tasnet.non_trainable_variables\n",
    "trainable_vars = 0\n",
    "non_trainable_vars = 0\n",
    "for trainable_list in trainable_lists:\n",
    "    trainable_vars += np.prod(trainable_list.shape)\n",
    "for non_trainable_list in non_trainable_lists:\n",
    "    non_trainable_vars += np.prod(non_trainable_list.shape)\n",
    "total_vars = trainable_vars + non_trainable_vars\n",
    "print('Total parameters:', total_vars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
