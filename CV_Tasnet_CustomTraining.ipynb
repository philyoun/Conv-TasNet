{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV_TasNet - Custom Training Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Unknownerror, cudnn 어쩌고저쩌고 에러\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import soundfile as sf\n",
    "sys.getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "num_spks = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_int(lst, size):\n",
    "    # 50800짜리 혹은 3000개짜리 리스트에서 뽑은 숫자는 빼고 다시 뽑아주는 함수\n",
    "    drawn, lst = lst[0:size],lst[size:]\n",
    "    return drawn, lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_normalize(tensor):\n",
    "    # tensor shape : (BATCH_SIZE, timesteps, num_spks)\n",
    "    scaled = tensor - tf.math.reduce_mean(tensor, axis=1, keepdims=True)\n",
    "    normalized = scaled / tf.math.reduce_std(tensor, axis=1, keepdims=True)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sisnr(predicted_batch, target_batch, BATCH_SIZE=BATCH_SIZE, num_spks=num_spks):\n",
    "    # 이렇다고 해도 여전히 3 speakers에 대해서는 안 됨. \n",
    "    N_predicted_batch = custom_normalize(predicted_batch) # (BS, length, 2)\n",
    "    N_target_batch = custom_normalize(target_batch) # (BS, length, 2)\n",
    "    \n",
    "    product = keras.layers.Dot(axes=(1, 1))([N_predicted_batch, N_target_batch]) # (BS, 2, 2)\n",
    "    \n",
    "    s_target_numerator = tf.zeros((1, num_spks, num_spks), dtype=tf.float32)\n",
    "    for i in range(BATCH_SIZE):\n",
    "        diag_part = tf.linalg.diag_part(product[i, :, :])\n",
    "        diag = tf.linalg.diag(diag_part)\n",
    "        diag = tf.expand_dims(diag, axis=0)\n",
    "        s_target_numerator = tf.concat([s_target_numerator, diag], axis=0)\n",
    "    s_target_numerator = s_target_numerator[1:, :, :] # discard first zeros, (BS, 2, 2)\n",
    "    \n",
    "    s_target_denominator = tf.zeros((1, 2, 2), dtype=tf.float32)\n",
    "    for i in range(BATCH_SIZE):\n",
    "        a1 = tf.norm(N_target_batch[i, :, 0])\n",
    "        b1 = tf.norm(N_target_batch[i, :, 1])\n",
    "        diag = tf.linalg.diag([tf.norm(N_target_batch[i, :, 0]), tf.norm(N_target_batch[i, :, 1])])\n",
    "        # 0인지 체크하는 부분은, 이제 4초짜리 segments들이기 때문에 사실 안 쓰일것임\n",
    "        # 4초동안 소리 없을리는 없잖아. 원래는 16/8000초짜리였음\n",
    "#         if a1 == 0:\n",
    "#             a1 = 1e-7\n",
    "#         if b1 == 0:\n",
    "#             b1 = 1e-7\n",
    "        diag = tf.linalg.diag([a1, b1])\n",
    "        diag = tf.linalg.inv(diag)\n",
    "        diag = tf.expand_dims(diag, axis=0)\n",
    "        s_target_denominator = tf.concat([s_target_denominator, diag], axis=0)\n",
    "    s_target_denominator = s_target_denominator[1:, :, :] # discard first zeros\n",
    "    \n",
    "    s_noise_vector = keras.layers.Dot(axes=2)([N_target_batch, s_target_numerator]) # 여기까지가 product * original_source인거고\n",
    "    s_noise = keras.layers.Dot(axes=2)([s_noise_vector, s_target_denominator]) # 이게 divided by norm\n",
    "    e_noise = N_predicted_batch - N_target_batch\n",
    "    si_snr = 10 * tf.experimental.numpy.log10(tf.norm(s_noise) / tf.norm(e_noise))\n",
    "    return si_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그럼 여기서는...input, target, target1의 리스트들만 뽑고\n",
    "def get_file_lst(drawn_numbers, input_files, target_files1, target_files2):\n",
    "    selected_train_input_files = [input_files[idx] for idx in drawn_numbers]\n",
    "    selected_train_target_files1 = [target_files1[idx] for idx in drawn_numbers]\n",
    "    selected_train_target_files2 = [target_files2[idx] for idx in drawn_numbers]\n",
    "    \n",
    "    return selected_train_input_files, selected_train_target_files1, selected_train_target_files2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds(input_segments, target_segments1, target_segments2):\n",
    "    general_ds = tf.data.Dataset.from_tensor_slices((input_segments, target_segments1, target_segments2))\n",
    "    general_ds = general_ds.batch(BATCH_SIZE, drop_remainder=True).shuffle(50000)\n",
    "#     general_ds = general_ds.map(lambda *x: tf.expand_dims(x, axis=-1))\n",
    "    general_ds = general_ds.map(lambda x, y, z: (tf.expand_dims(x, axis=-1), tf.expand_dims(y, axis=-1), tf.expand_dims(z, axis=-1)))\n",
    "    general_ds = general_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return general_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "# BATCH_SIZE = 64\n",
    "# num_spks = 2\n",
    "# target = tf.random.normal((BATCH_SIZE, 32000, 2))\n",
    "# pred = tf.random.normal((BATCH_SIZE, 32000, 2))\n",
    "# calculate_sisnr(target, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
